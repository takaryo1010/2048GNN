[2025-08-15 08:08:46][base_learner.py:360][INFO] [RANK0]: DI-engine DRL Policy
GATStochasticMuZeroModel(
  (representation_network): GATRepresentationNetwork(
    (input_proj): Linear(in_features=16, out_features=64, bias=True)
    (gat_layers): ModuleList(
      (0): GATConv(64, 64, heads=4)
      (1-2): 2 x GATConv(256, 64, heads=4)
    )
    (output_proj): Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=256, bias=True)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (afterstate_dynamics_network): GATAfterstateDynamicsNetwork(
    (action_embedding): Embedding(4, 64)
    (state_action_fusion): Sequential(
      (0): Linear(in_features=320, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=128, bias=True)
      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=256, bias=True)
      (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (8): ReLU()
    )
    (to_grid_proj): Linear(in_features=256, out_features=144, bias=True)
    (gat_afterstate): GATRepresentationNetwork(
      (input_proj): Linear(in_features=16, out_features=64, bias=True)
      (gat_layers): ModuleList(
        (0): GATConv(64, 64, heads=4)
        (1): GATConv(256, 64, heads=4)
      )
      (output_proj): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (chance_encoder): GATChanceEncoder(
    (chance_embedding): Embedding(18, 64)
    (gat_chance): GATRepresentationNetwork(
      (input_proj): Linear(in_features=32, out_features=64, bias=True)
      (gat_layers): ModuleList(
        (0): GATConv(64, 64, heads=4)
        (1): GATConv(256, 64, heads=4)
      )
      (output_proj): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (chance_fusion): Sequential(
      (0): Linear(in_features=320, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
  )
  (state_to_grid_projection): Linear(in_features=256, out_features=144, bias=True)
  (reward_head_afterstate): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=601, bias=True)
  )
  (value_head): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=601, bias=True)
  )
  (policy_head): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=4, bias=True)
  )
  (afterstate_policy_head): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=18, bias=True)
  )
)
[2025-08-15 08:09:16][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./data_quick_transfer/phase1_3x3_quick_test_250815_080845/ckpt/ckpt_best.pth.tar
[2025-08-15 08:10:22][base_learner.py:360][INFO] [RANK0]: === Training Iteration 0 Result ===
[2025-08-15 08:10:22][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 60.971962               | 72.685074      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 8.111988        | 31.992973       | 38.391567      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 14.451859                  | 31.992973                 | 0.532118            | 78.433731          |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.093750          | 79.494690        | -0.000006             | -0.000006            |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.505021                      | 7.526626                     | 1.850242                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 08:10:22][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./data_quick_transfer/phase1_3x3_quick_test_250815_080845/ckpt/iteration_0.pth.tar
