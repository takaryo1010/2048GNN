[2025-08-05 14:39:42][base_learner.py:360][INFO] [RANK0]: DI-engine DRL Policy
GATMuZeroModel(
  (representation_network): GATRepresentationNetwork(
    (input_proj): Linear(in_features=16, out_features=64, bias=True)
    (gat_layers): ModuleList(
      (0): GATConv(64, 64, heads=4)
      (1-2): 2 x GATConv(256, 64, heads=4)
    )
    (output_proj): Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=256, bias=True)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (dynamics_network): GATDynamicsNetwork(
    (action_embedding): Embedding(4, 64)
    (state_action_fusion): Sequential(
      (0): Linear(in_features=320, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=128, bias=True)
      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=256, bias=True)
      (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (8): ReLU()
    )
    (to_grid_proj): Linear(in_features=256, out_features=256, bias=True)
    (gat_dynamics): GATRepresentationNetwork(
      (input_proj): Linear(in_features=16, out_features=64, bias=True)
      (gat_layers): ModuleList(
        (0): GATConv(64, 64, heads=4)
        (1): GATConv(256, 64, heads=4)
      )
      (output_proj): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (reward_head): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
      (6): Linear(in_features=64, out_features=601, bias=True)
      (7): LayerNorm((601,), eps=1e-05, elementwise_affine=True)
      (8): ReLU()
    )
  )
  (value_head): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=601, bias=True)
  )
  (policy_head): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=4, bias=True)
  )
)
[2025-08-05 14:40:23][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./data_gat/game_2048_grid4_gat_ns100_upc200_rer0.0_bs512_heads4_seed0_250805_143937/ckpt/ckpt_best.pth.tar
[2025-08-05 14:42:01][base_learner.py:360][INFO] [RANK0]: === Training Iteration 0 Result ===
[2025-08-05 14:42:01][learner_hook.py:228][INFO] 
+-------+------------------------------------+-------------------------------------+------------------------------------+-----------------------------+
| Name  | analysis/dormant_ratio_encoder_avg | analysis/dormant_ratio_dynamics_avg | analysis/latent_state_l2_norms_avg | analysis/l2_norm_before_avg |
+-------+------------------------------------+-------------------------------------+------------------------------------+-----------------------------+
| Value | 0.000000                           | 0.000000                            | 11.419665                          | 0.000000                    |
+-------+------------------------------------+-------------------------------------+------------------------------------+-----------------------------+
+-------+----------------------------+-------------------------------+------------------------------+------------------------------+
| Name  | analysis/l2_norm_after_avg | analysis/grad_norm_before_avg | analysis/grad_norm_after_avg | collect_mcts_temperature_avg |
+-------+----------------------------+-------------------------------+------------------------------+------------------------------+
| Value | 0.000000                   | 0.000000                      | 0.000000                     | 1.000000                     |
+-------+----------------------------+-------------------------------+------------------------------+------------------------------+
+-------+------------+-------------------------+----------------+-----------------+
| Name  | cur_lr_avg | weighted_total_loss_avg | total_loss_avg | policy_loss_avg |
+-------+------------+-------------------------+----------------+-----------------+
| Value | 0.003000   | 51.692146               | 51.692146      | 8.055128        |
+-------+------------+-------------------------+----------------+-----------------+
+-------+--------------------+---------------------------+-----------------+----------------+
| Name  | policy_entropy_avg | target_policy_entropy_avg | reward_loss_avg | value_loss_avg |
+-------+--------------------+---------------------------+-----------------+----------------+
| Value | 1.386294           | 1.151083                  | 34.039124       | 38.391567      |
+-------+--------------------+---------------------------+-----------------+----------------+
+-------+----------------------+--------------------+-------------------+------------------+
| Name  | consistency_loss_avg | value_priority_avg | target_reward_avg | target_value_avg |
+-------+----------------------+--------------------+-------------------+------------------+
| Value | 0.000000             | 76.862389          | 7.856771          | 75.102287        |
+-------+----------------------+--------------------+-------------------+------------------+
+-------+-----------------------+----------------------+-------------------------------+------------------------------+
| Name  | predicted_rewards_avg | predicted_values_avg | transformed_target_reward_avg | transformed_target_value_avg |
+-------+-----------------------+----------------------+-------------------------------+------------------------------+
| Value | -43.503410            | -0.000006            | 1.459845                      | 7.268672                     |
+-------+-----------------------+----------------------+-------------------------------+------------------------------+
+-------+---------------------------------+
| Name  | total_grad_norm_before_clip_avg |
+-------+---------------------------------+
| Value | 13.329606                       |
+-------+---------------------------------+

[2025-08-05 14:42:01][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./data_gat/game_2048_grid4_gat_ns100_upc200_rer0.0_bs512_heads4_seed0_250805_143937/ckpt/iteration_0.pth.tar
[2025-08-05 14:44:10][base_learner.py:360][INFO] [RANK0]: === Training Iteration 100 Result ===
[2025-08-05 14:44:10][learner_hook.py:228][INFO] 
+-------+------------------------------------+-------------------------------------+------------------------------------+-----------------------------+
| Name  | analysis/dormant_ratio_encoder_avg | analysis/dormant_ratio_dynamics_avg | analysis/latent_state_l2_norms_avg | analysis/l2_norm_before_avg |
+-------+------------------------------------+-------------------------------------+------------------------------------+-----------------------------+
| Value | 0.000000                           | 0.000000                            | 9.961990                           | 0.000000                    |
+-------+------------------------------------+-------------------------------------+------------------------------------+-----------------------------+
+-------+----------------------------+-------------------------------+------------------------------+------------------------------+
| Name  | analysis/l2_norm_after_avg | analysis/grad_norm_before_avg | analysis/grad_norm_after_avg | collect_mcts_temperature_avg |
+-------+----------------------------+-------------------------------+------------------------------+------------------------------+
| Value | 0.000000                   | 0.000000                      | 0.000000                     | 1.000000                     |
+-------+----------------------------+-------------------------------+------------------------------+------------------------------+
+-------+------------+-------------------------+----------------+-----------------+
| Name  | cur_lr_avg | weighted_total_loss_avg | total_loss_avg | policy_loss_avg |
+-------+------------+-------------------------+----------------+-----------------+
| Value | 0.003000   | 20.062770               | 20.062770      | 8.078727        |
+-------+------------+-------------------------+----------------+-----------------+
+-------+--------------------+---------------------------+-----------------+----------------+
| Name  | policy_entropy_avg | target_policy_entropy_avg | reward_loss_avg | value_loss_avg |
+-------+--------------------+---------------------------+-----------------+----------------+
| Value | 1.385352           | 1.151107                  | 8.215025        | 15.076074      |
+-------+--------------------+---------------------------+-----------------+----------------+
+-------+----------------------+--------------------+-------------------+------------------+
| Name  | consistency_loss_avg | value_priority_avg | target_reward_avg | target_value_avg |
+-------+----------------------+--------------------+-------------------+------------------+
| Value | 0.000000             | 39.674299          | 7.861743          | 81.806045        |
+-------+----------------------+--------------------+-------------------+------------------+
+-------+-----------------------+----------------------+-------------------------------+------------------------------+
| Name  | predicted_rewards_avg | predicted_values_avg | transformed_target_reward_avg | transformed_target_value_avg |
+-------+-----------------------+----------------------+-------------------------------+------------------------------+
| Value | 4.931090              | 64.257839            | 1.464062                      | 7.621075                     |
+-------+-----------------------+----------------------+-------------------------------+------------------------------+
+-------+---------------------------------+
| Name  | total_grad_norm_before_clip_avg |
+-------+---------------------------------+
| Value | 0.295978                        |
+-------+---------------------------------+

