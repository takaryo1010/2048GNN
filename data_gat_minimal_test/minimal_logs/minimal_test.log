2025-08-15 06:30:35,320 - WARNING - If you want to use numba to speed up segment tree, please install numba first
2025-08-15 06:30:35,430 - WARNING - Please install pyecharts first, you can install it by running 'pip install pyecharts'
2025-08-15 06:30:35,750 - WARNING - not found transformer, please install it using: pip install transformers
2025-08-15 06:30:37,703 - INFO - Generating grammar tables from /usr/lib/python3.8/lib2to3/Grammar.txt
2025-08-15 06:30:37,719 - INFO - Generating grammar tables from /usr/lib/python3.8/lib2to3/PatternGrammar.txt
2025-08-15 06:30:38,583 - INFO - [RANK0]: DI-engine DRL Policy
GATStochasticMuZeroModel(
  (representation_network): GATRepresentationNetwork(
    (input_proj): Linear(in_features=16, out_features=16, bias=True)
    (gat_layers): ModuleList(
      (0): GATConv(16, 16, heads=1)
    )
    (output_proj): Sequential(
      (0): Linear(in_features=16, out_features=32, bias=True)
      (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=32, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
    (activation): ReLU()
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (afterstate_dynamics_network): GATAfterstateDynamicsNetwork(
    (action_embedding): Embedding(4, 16)
    (state_action_fusion): Sequential(
      (0): Linear(in_features=80, out_features=32, bias=True)
      (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=32, out_features=32, bias=True)
      (4): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=64, bias=True)
      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (8): ReLU()
    )
    (to_grid_proj): Linear(in_features=64, out_features=144, bias=True)
    (gat_afterstate): GATRepresentationNetwork(
      (input_proj): Linear(in_features=16, out_features=16, bias=True)
      (gat_layers): ModuleList()
      (output_proj): Sequential(
        (0): Linear(in_features=16, out_features=32, bias=True)
        (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=32, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (chance_encoder): GATChanceEncoder(
    (chance_embedding): Embedding(18, 16)
    (gat_chance): GATRepresentationNetwork(
      (input_proj): Linear(in_features=32, out_features=16, bias=True)
      (gat_layers): ModuleList()
      (output_proj): Sequential(
        (0): Linear(in_features=16, out_features=32, bias=True)
        (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=32, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (chance_fusion): Sequential(
      (0): Linear(in_features=80, out_features=64, bias=True)
      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
  )
  (state_to_grid_projection): Linear(in_features=64, out_features=144, bias=True)
  (reward_head_afterstate): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=8, out_features=101, bias=True)
  )
  (value_head): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=8, out_features=101, bias=True)
  )
  (policy_head): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=8, out_features=4, bias=True)
  )
  (afterstate_policy_head): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=8, out_features=18, bias=True)
  )
)
2025-08-15 06:34:41,746 - WARNING - If you want to use numba to speed up segment tree, please install numba first
2025-08-15 06:34:41,855 - WARNING - Please install pyecharts first, you can install it by running 'pip install pyecharts'
2025-08-15 06:34:42,167 - WARNING - not found transformer, please install it using: pip install transformers
2025-08-15 06:34:44,211 - INFO - Generating grammar tables from /usr/lib/python3.8/lib2to3/Grammar.txt
2025-08-15 06:34:44,233 - INFO - Generating grammar tables from /usr/lib/python3.8/lib2to3/PatternGrammar.txt
2025-08-15 06:34:45,196 - INFO - [RANK0]: DI-engine DRL Policy
GATStochasticMuZeroModel(
  (representation_network): GATRepresentationNetwork(
    (input_proj): Linear(in_features=16, out_features=16, bias=True)
    (gat_layers): ModuleList(
      (0): GATConv(16, 16, heads=1)
    )
    (output_proj): Sequential(
      (0): Linear(in_features=16, out_features=32, bias=True)
      (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=32, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
    (activation): ReLU()
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (afterstate_dynamics_network): GATAfterstateDynamicsNetwork(
    (action_embedding): Embedding(4, 16)
    (state_action_fusion): Sequential(
      (0): Linear(in_features=80, out_features=32, bias=True)
      (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=32, out_features=32, bias=True)
      (4): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
      (6): Linear(in_features=32, out_features=64, bias=True)
      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (8): ReLU()
    )
    (to_grid_proj): Linear(in_features=64, out_features=144, bias=True)
    (gat_afterstate): GATRepresentationNetwork(
      (input_proj): Linear(in_features=16, out_features=16, bias=True)
      (gat_layers): ModuleList()
      (output_proj): Sequential(
        (0): Linear(in_features=16, out_features=32, bias=True)
        (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=32, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (chance_encoder): GATChanceEncoder(
    (chance_embedding): Embedding(18, 16)
    (gat_chance): GATRepresentationNetwork(
      (input_proj): Linear(in_features=32, out_features=16, bias=True)
      (gat_layers): ModuleList()
      (output_proj): Sequential(
        (0): Linear(in_features=16, out_features=32, bias=True)
        (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=32, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (chance_fusion): Sequential(
      (0): Linear(in_features=80, out_features=64, bias=True)
      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
  )
  (state_to_grid_projection): Linear(in_features=64, out_features=144, bias=True)
  (reward_head_afterstate): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=8, out_features=601, bias=True)
  )
  (value_head): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=8, out_features=601, bias=True)
  )
  (policy_head): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=8, out_features=4, bias=True)
  )
  (afterstate_policy_head): Sequential(
    (0): Linear(in_features=64, out_features=8, bias=True)
    (1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=8, out_features=18, bias=True)
  )
)
2025-08-15 06:34:47,828 - INFO - [EVALUATOR]env 0 finish episode, final reward: 1028.0, current episode: 1
2025-08-15 06:34:47,833 - INFO - 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 1.000000      | 113.000000    |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 113.000000              | 2.795241      | 40.425856           | 0.357751             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+-------------+-------------+
| Name  | reward_mean | reward_std | reward_max  | reward_min  |
+-------+-------------+------------+-------------+-------------+
| Value | 1028.000000 | 0.000000   | 1028.000000 | 1028.000000 |
+-------+-------------+------------+-------------+-------------+
+-------+---------------------+--------------------------+
| Name  | eval_episode_return | eval_episode_return_mean |
+-------+---------------------+--------------------------+
| Value | [1028.0]            | 1028.000000              |
+-------+---------------------+--------------------------+

2025-08-15 06:34:47,857 - INFO - [RANK0]: learner save ckpt in ./gat_minimal_test_3x3_250815_063444/ckpt/ckpt_best.pth.tar
