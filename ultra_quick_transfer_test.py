#!/usr/bin/env python3
"""
è¶…è»½é‡è»¢ç§»å­¦ç¿’ãƒ†ã‚¹ãƒˆ (è¶…çŸ­æ™‚é–“å®Ÿè¡Œç‰ˆ)
3Ã—3ã§2åˆ†ç¨‹åº¦å­¦ç¿’ â†’ 4Ã—4ã«1åˆ†ç¨‹åº¦è»¢ç§»å­¦ç¿’ã®ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import torch
import logging
import argparse
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "LightZero"))

from easydict import EasyDict


def create_ultra_light_3x3_config():
    """3Ã—3ã‚°ãƒªãƒƒãƒ‰ç”¨ã®è¶…è»½é‡ãƒ†ã‚¹ãƒˆè¨­å®š"""
    
    config = dict(
        exp_name='data_ultra_quick_transfer/phase1_3x3_ultra_quick',
        env=dict(
            stop_value=int(1e6),
            env_id='game_2048',
            obs_shape=(16, 3, 3),
            obs_type='dict_encoded_board',
            num_of_possible_chance_tile=2,
            collector_env_num=2,  # ã•ã‚‰ã«è»½é‡åŒ–ï¼ˆ4â†’2ï¼‰
            evaluator_env_num=1,
            n_evaluator_episode=1,
            manager=dict(shared_memory=False, ),
        ),
        policy=dict(
            type='stochastic_muzero',
            model=dict(
                type='GATStochasticMuZeroModel',
                model_type='gat',
                model='gat_stochastic',
                observation_shape=(16, 3, 3),
                image_channel=16,
                action_space_size=4,
                chance_space_size=18,  # 3*3*2
                frame_stack_num=1,
                
                # GAT parameters - è»½é‡åŒ–
                num_heads=2,  # 4â†’2ã«å‰Šæ¸›
                hidden_channels=32,  # 64â†’32ã«å‰Šæ¸›
                num_gat_layers=2,  # 3â†’2ã«å‰Šæ¸›
                state_dim=128,  # 256â†’128ã«å‰Šæ¸›
                dropout=0.1,
                
                # StochasticMuZero parameters
                chance_encoder_num_layers=1,  # 2â†’1ã«å‰Šæ¸›
                afterstate_reward_layers=1,  # 2â†’1ã«å‰Šæ¸›
                
                # Standard parameters - è»½é‡åŒ–
                value_head_channels=8,  # 16â†’8ã«å‰Šæ¸›
                policy_head_channels=8,  # 16â†’8ã«å‰Šæ¸›
                value_head_hidden_channels=[16],  # [32]â†’[16]ã«å‰Šæ¸›
                policy_head_hidden_channels=[16],  # [32]â†’[16]ã«å‰Šæ¸›
                
                flatten_input_size_for_value_head=128,  # 256â†’128ã«å‰Šæ¸›
                flatten_input_size_for_policy_head=128,  # 256â†’128ã«å‰Šæ¸›
                
                reward_support_size=601,
                value_support_size=601,
                categorical_distribution=True,
                last_linear_layer_init_zero=True,
                state_norm=False,
                self_supervised_learning_loss=True,
            ),
            model_path=None,
            use_ture_chance_label_in_chance_encoder=True,
            cuda=True,
            game_segment_length=50,  # 200â†’50ã«å¤§å¹…å‰Šæ¸›
            update_per_collect=10,  # 50â†’10ã«å¤§å¹…å‰Šæ¸›
            batch_size=32,  # 128â†’32ã«å¤§å¹…å‰Šæ¸›
            td_steps=5,  # 10â†’5ã«å‰Šæ¸›
            discount_factor=0.999,
            manual_temperature_decay=True,
            optim_type='Adam',
            piecewise_decay_lr_scheduler=False,
            learning_rate=0.005,  # 0.003â†’0.005ã«å¢—åŠ ï¼ˆé«˜é€Ÿå­¦ç¿’ï¼‰
            weight_decay=1e-4,
            num_simulations=20,  # 50â†’20ã«å¤§å¹…å‰Šæ¸›
            reanalyze_ratio=0.,
            ssl_loss_weight=0,
            stochastic_loss_weight=1.0,
            n_episode=2,  # 4â†’2ã«å‰Šæ¸›
            eval_freq=int(2e3),  # 1e4â†’2e3ã«å‰Šæ¸›ï¼ˆé »ç¹ã«è©•ä¾¡ï¼‰
            replay_buffer_size=int(5e3),  # 1e5â†’5e3ã«å¤§å¹…å‰Šæ¸›
            collector_env_num=2,
            evaluator_env_num=1,
        ),
    )
    
    return EasyDict(config)


def create_ultra_light_4x4_config(pretrained_path):
    """4Ã—4ã‚°ãƒªãƒƒãƒ‰ç”¨ã®è¶…è»½é‡è»¢ç§»å­¦ç¿’è¨­å®š"""
    
    config = dict(
        exp_name='data_ultra_quick_transfer/phase2_4x4_ultra_quick_transfer',
        env=dict(
            stop_value=int(1e6),
            env_id='game_2048',
            obs_shape=(16, 4, 4),
            obs_type='dict_encoded_board',
            num_of_possible_chance_tile=2,
            collector_env_num=2,
            evaluator_env_num=1,
            n_evaluator_episode=1,
            manager=dict(shared_memory=False, ),
        ),
        policy=dict(
            type='stochastic_muzero',
            model=dict(
                type='GATStochasticMuZeroModel',
                model_type='gat',
                model='gat_stochastic',
                observation_shape=(16, 4, 4),
                image_channel=16,
                action_space_size=4,
                chance_space_size=32,  # 4*4*2
                frame_stack_num=1,
                
                # GAT parameters (3Ã—3ã¨åŒã˜è»½é‡è¨­å®š)
                num_heads=2,
                hidden_channels=32,
                num_gat_layers=2,
                state_dim=128,
                dropout=0.1,
                
                # StochasticMuZero parameters
                chance_encoder_num_layers=1,
                afterstate_reward_layers=1,
                
                # Standard parameters
                value_head_channels=8,
                policy_head_channels=8,
                value_head_hidden_channels=[16],
                policy_head_hidden_channels=[16],
                
                flatten_input_size_for_value_head=128,
                flatten_input_size_for_policy_head=128,
                
                reward_support_size=601,
                value_support_size=601,
                categorical_distribution=True,
                last_linear_layer_init_zero=True,
                state_norm=False,
                self_supervised_learning_loss=True,
            ),
            model_path=pretrained_path,  # è»¢ç§»å­¦ç¿’ç”¨
            use_ture_chance_label_in_chance_encoder=True,
            cuda=True,
            game_segment_length=50,
            update_per_collect=10,
            batch_size=32,
            td_steps=5,
            discount_factor=0.999,
            manual_temperature_decay=True,
            optim_type='Adam',
            piecewise_decay_lr_scheduler=False,
            learning_rate=0.002,  # è»¢ç§»å­¦ç¿’ã§ã¯0.005â†’0.002ã«å‰Šæ¸›
            weight_decay=1e-4,
            num_simulations=20,
            reanalyze_ratio=0.,
            ssl_loss_weight=0,
            stochastic_loss_weight=1.0,
            n_episode=2,
            eval_freq=int(2e3),
            replay_buffer_size=int(5e3),
            collector_env_num=2,
            evaluator_env_num=1,
        ),
    )
    
    return EasyDict(config)


def get_create_config():
    """å…±é€šã®create_config"""
    return EasyDict(dict(
        env=dict(
            type='game_2048',
            import_names=['zoo.game_2048.envs.game_2048_env'],
        ),
        env_manager=dict(type='subprocess'),
        policy=dict(
            type='stochastic_muzero',
            import_names=['lzero.policy.stochastic_muzero'],
        ),
        model=dict(
            type='GATStochasticMuZeroModel',
            import_names=['lzero.model.gat_stochastic_muzero_model'],
        ),
    ))


def main():
    """è¶…è»½é‡è»¢ç§»å­¦ç¿’ãƒ†ã‚¹ãƒˆ"""
    
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        from lzero.entry import train_muzero
        from lzero.model.gat_stochastic_muzero_model import GATStochasticMuZeroModel
        logger.info("âœ… LightZero ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    print("=" * 70)
    print("âš¡ GATè»¢ç§»å­¦ç¿’ è¶…è»½é‡ãƒ†ã‚¹ãƒˆ")
    print("ğŸš€ è¶…çŸ­æ™‚é–“å®Ÿè¡Œç‰ˆ (3Ã—3 â†’ 4Ã—4)")
    print("=" * 70)
    print("ğŸ“Š è»½é‡åŒ–è¨­å®š:")
    print("  - ç’°å¢ƒæ•°: 2 (é€šå¸¸8)")
    print("  - ãƒãƒƒãƒã‚µã‚¤ã‚º: 32 (é€šå¸¸512)")
    print("  - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: 20 (é€šå¸¸100)")
    print("  - GATå±¤: 2 (é€šå¸¸3)")
    print("  - éš ã‚Œæ¬¡å…ƒ: 128 (é€šå¸¸256)")
    print("  - ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆé »åº¦: 10 (é€šå¸¸200)")
    print("=" * 70)
    
    # Phase 1: 3Ã—3è¶…è»½é‡å­¦ç¿’
    print("\nğŸ”µ Phase 1: 3Ã—3è¶…è»½é‡å­¦ç¿’")
    config_3x3 = create_ultra_light_3x3_config()
    create_config = get_create_config()
    
    print(f"âœ“ å®Ÿé¨“å: {config_3x3.exp_name}")
    print(f"âœ“ ãƒãƒ£ãƒ³ã‚¹ç©ºé–“: {config_3x3.policy.model.chance_space_size}")
    print(f"âœ“ è¶…è»½é‡è¨­å®š: ãƒãƒƒãƒ{config_3x3.policy.batch_size}, ã‚·ãƒŸãƒ¥{config_3x3.policy.num_simulations}")
    print(f"âœ“ ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—: {int(5e3)} (éå¸¸ã«çŸ­æ™‚é–“)")
    
    try:
        print("ğŸš€ 3Ã—3è¶…è»½é‡å­¦ç¿’é–‹å§‹...")
        train_muzero([config_3x3, create_config], seed=0, model_path=None, max_env_step=int(5e3))  # éå¸¸ã«çŸ­æ™‚é–“
        print("âœ… 3Ã—3å­¦ç¿’å®Œäº†")
    except Exception as e:
        logger.error(f"âŒ 3Ã—3å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ¤œç´¢
    import glob
    checkpoint_pattern = "./data_ultra_quick_transfer/phase1_3x3_**/ckpt_*.pth.tar"
    checkpoints = glob.glob(checkpoint_pattern, recursive=True)
    
    if not checkpoints:
        logger.error("âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    latest_checkpoint = max(checkpoints, key=os.path.getctime)
    print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç™ºè¦‹: {latest_checkpoint}")
    
    # Phase 2: 4Ã—4è»¢ç§»å­¦ç¿’
    print("\nğŸ”´ Phase 2: 4Ã—4è¶…è»½é‡è»¢ç§»å­¦ç¿’")
    config_4x4 = create_ultra_light_4x4_config(latest_checkpoint)
    
    print(f"âœ“ å®Ÿé¨“å: {config_4x4.exp_name}")
    print(f"âœ“ ãƒãƒ£ãƒ³ã‚¹ç©ºé–“: {config_4x4.policy.model.chance_space_size}")
    print(f"âœ“ ãƒ—ãƒªãƒˆãƒ¬ã‚¤ãƒ³: {latest_checkpoint}")
    print(f"âœ“ ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—: {int(3e3)} (çŸ­æ™‚é–“)")
    
    try:
        print("ğŸš€ 4Ã—4è»¢ç§»å­¦ç¿’é–‹å§‹...")
        train_muzero([config_4x4, create_config], seed=0, model_path=latest_checkpoint, max_env_step=int(3e3))
        print("âœ… 4Ã—4è»¢ç§»å­¦ç¿’å®Œäº†")
    except Exception as e:
        logger.error(f"âŒ 4Ã—4è»¢ç§»å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    print("\nğŸ‰ è¶…è»½é‡è»¢ç§»å­¦ç¿’ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
    print("â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: ç´„3-5åˆ†ã‚’æƒ³å®š")
    print("=" * 70)
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
