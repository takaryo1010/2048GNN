[2025-08-15 10:14:23][base_learner.py:360][INFO] [RANK0]: DI-engine DRL Policy
GATStochasticMuZeroModel(
  (representation_network): GATRepresentationNetwork(
    (input_proj): Linear(in_features=16, out_features=64, bias=True)
    (gat_layers): ModuleList(
      (0): GATConv(64, 64, heads=4)
      (1-2): 2 x GATConv(256, 64, heads=4)
    )
    (output_proj): Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=256, bias=True)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (afterstate_dynamics_network): GATAfterstateDynamicsNetwork(
    (action_embedding): Embedding(4, 64)
    (state_action_fusion): Sequential(
      (0): Linear(in_features=320, out_features=128, bias=True)
      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=128, bias=True)
      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=256, bias=True)
      (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (8): ReLU()
    )
    (to_grid_proj): Linear(in_features=256, out_features=144, bias=True)
    (gat_afterstate): GATRepresentationNetwork(
      (input_proj): Linear(in_features=16, out_features=64, bias=True)
      (gat_layers): ModuleList(
        (0): GATConv(64, 64, heads=4)
        (1): GATConv(256, 64, heads=4)
      )
      (output_proj): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (chance_encoder): GATChanceEncoder(
    (chance_embedding): Embedding(18, 64)
    (gat_chance): GATRepresentationNetwork(
      (input_proj): Linear(in_features=32, out_features=64, bias=True)
      (gat_layers): ModuleList(
        (0): GATConv(64, 64, heads=4)
        (1): GATConv(256, 64, heads=4)
      )
      (output_proj): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): ReLU()
        (3): Linear(in_features=128, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU()
      )
      (activation): ReLU()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (chance_fusion): Sequential(
      (0): Linear(in_features=320, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (2): ReLU()
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (5): ReLU()
    )
  )
  (state_to_grid_projection): Linear(in_features=256, out_features=144, bias=True)
  (reward_head_afterstate): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=601, bias=True)
  )
  (value_head): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=601, bias=True)
  )
  (policy_head): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=4, bias=True)
  )
  (afterstate_policy_head): Sequential(
    (0): Linear(in_features=256, out_features=32, bias=True)
    (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=18, bias=True)
  )
)
[2025-08-15 10:14:47][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./data_gat_transfer/phase1_3x3_gat_stochastic_ns100_upc200_rer0.0_bs512_heads4_seed0_250815_101421/ckpt/ckpt_best.pth.tar
[2025-08-15 10:17:12][base_learner.py:360][INFO] [RANK0]: === Training Iteration 0 Result ===
[2025-08-15 10:17:12][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 64.470428               | 72.563538      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.998269        | 31.992973       | 38.391567      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 14.451859                  | 31.992973                 | 0.524306            | 67.148499          |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 6.854167          | 66.006027        | -0.000006             | -0.000006            |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.297868                      | 6.610244                     | 2.091417                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:17:12][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./data_gat_transfer/phase1_3x3_gat_stochastic_ns100_upc200_rer0.0_bs512_heads4_seed0_250815_101421/ckpt/iteration_0.pth.tar
[2025-08-15 10:19:45][base_learner.py:360][INFO] [RANK0]: === Training Iteration 100 Result ===
[2025-08-15 10:19:45][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 14.711360               | 37.596489      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 8.071472        | 8.054868        | 15.718311      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.744177                  | 13.086224                 | 0.524838            | 39.533538          |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 7.029711          | 70.987685        | 3.647308              | 49.945889            |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.327653                      | 6.916023                     | 0.090312                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:25:43][base_learner.py:360][INFO] [RANK0]: === Training Iteration 200 Result ===
[2025-08-15 10:25:43][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 17.150232               | 37.063661      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 8.032714        | 7.901237        | 14.845100      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.754099                  | 12.561858                 | 0.523872            | 47.636972          |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 7.097420          | 109.885440       | 4.079042              | 91.452294            |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.331219                      | 8.925567                     | 0.107739                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:28:33][base_learner.py:360][INFO] [RANK0]: === Training Iteration 300 Result ===
[2025-08-15 10:28:33][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 13.099945               | 37.423562      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.880114        | 8.307917        | 15.144794      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.701350                  | 12.890680                 | 0.525312            | 78.056761          |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.668206          | 154.873220       | 4.964235              | 128.443682           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.490876                      | 10.541798                    | 0.080091                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:34:41][base_learner.py:360][INFO] [RANK0]: === Training Iteration 400 Result ===
[2025-08-15 10:34:41][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 13.397078               | 37.046864      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.864696        | 8.252671        | 14.394115      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.722300                  | 12.331061                 | 0.525904            | 87.954541          |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.529356          | 183.156842       | 4.898855              | 157.219166           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.472304                      | 11.539351                    | 0.089823                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:37:26][base_learner.py:360][INFO] [RANK0]: === Training Iteration 500 Result ===
[2025-08-15 10:37:26][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 14.162768               | 36.910041      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.851476        | 8.290517        | 14.055366      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.731891                  | 11.988178                 | 0.525272            | 98.092886          |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.485204          | 205.566187       | 4.969408              | 179.475607           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.486347                      | 12.305290                    | 0.085159                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:42:17][base_learner.py:360][INFO] [RANK0]: === Training Iteration 600 Result ===
[2025-08-15 10:42:17][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 12.931158               | 36.816255      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.881310        | 8.266727        | 13.859238      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.713752                  | 11.861484                 | 0.524286            | 104.910327         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.399740          | 223.525515       | 5.024230              | 197.376812           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.479539                      | 12.862201                    | 0.083660                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:44:48][base_learner.py:360][INFO] [RANK0]: === Training Iteration 700 Result ===
[2025-08-15 10:44:48][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 18.207060               | 36.720366      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.863558        | 8.236856        | 13.652290      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.751808                  | 11.723853                 | 0.524108            | 106.693351         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.203480          | 231.571217       | 4.933913              | 204.482941           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.465260                      | 13.167834                    | 0.125776                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:49:43][base_learner.py:360][INFO] [RANK0]: === Training Iteration 800 Result ===
[2025-08-15 10:49:43][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 17.425713               | 36.797815      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.916712        | 8.279830        | 13.609521      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.744822                  | 11.718351                 | 0.524483            | 108.795632         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.268821          | 243.710280       | 5.078856              | 217.045733           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.474699                      | 13.574255                    | 0.122438                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:52:13][base_learner.py:360][INFO] [RANK0]: === Training Iteration 900 Result ===
[2025-08-15 10:52:13][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.264804               | 36.819323      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.886570        | 8.297088        | 13.647770      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.767170                  | 11.720067                 | 0.526535            | 114.207875         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.354877          | 251.584308       | 5.003877              | 225.938979           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.484085                      | 13.758965                    | 0.135454                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:57:11][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1000 Result ===
[2025-08-15 10:57:11][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.676735               | 36.685104      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.861559        | 8.216914        | 13.554649      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.776798                  | 11.663672                 | 0.525253            | 116.126730         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.188447          | 254.066377       | 4.990182              | 227.569401           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.456926                      | 13.795004                    | 0.135080                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 10:59:43][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1100 Result ===
[2025-08-15 10:59:43][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.843287               | 36.703568      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.871503        | 8.207989        | 13.596233      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.783873                  | 11.668222                 | 0.524089            | 117.749654         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.100971          | 254.525310       | 4.954560              | 226.341123           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.455218                      | 13.823253                    | 0.140589                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:04:39][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1200 Result ===
[2025-08-15 11:04:39][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.712625               | 36.639424      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.869109        | 8.203546        | 13.520613      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.766991                  | 11.581041                 | 0.524365            | 119.718242         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.157434          | 258.622667       | 4.892878              | 229.880728           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.455996                      | 13.942213                    | 0.143058                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:07:09][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1300 Result ===
[2025-08-15 11:07:09][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 23.255994               | 36.568716      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.850843        | 8.181454        | 13.398209      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.796690                  | 11.459777                 | 0.525233            | 118.911445         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 7.978930          | 262.379383       | 4.874194              | 236.464383           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.442549                      | 14.057565                    | 0.158558                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:12:58][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1400 Result ===
[2025-08-15 11:12:58][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.991421               | 36.604872      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.843352        | 8.187988        | 13.498629      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.784325                  | 11.562632                 | 0.523891            | 124.284234         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.047112          | 262.980974       | 4.921258              | 231.246253           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.448616                      | 14.023855                    | 0.134882                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:15:35][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1500 Result ===
[2025-08-15 11:15:35][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.081915               | 36.671547      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.831182        | 8.176233        | 13.587364      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.832502                  | 11.640746                 | 0.524601            | 121.215632         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.101681          | 260.991082       | 4.897521              | 237.545492           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.445154                      | 13.946943                    | 0.135367                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:20:41][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1600 Result ===
[2025-08-15 11:20:41][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.235609               | 36.687971      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.839565        | 8.201916        | 13.625777      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.799991                  | 11.663075                 | 0.524286            | 120.425715         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.162050          | 261.446429       | 4.922406              | 232.339355           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.458650                      | 14.012509                    | 0.160895                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:23:06][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1700 Result ===
[2025-08-15 11:23:06][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.255676               | 36.775329      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.862580        | 8.268250        | 13.602931      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.810325                  | 11.638990                 | 0.523694            | 120.310738         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.326350          | 266.756478       | 4.986807              | 237.527937           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.482930                      | 14.198020                    | 0.148706                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:27:49][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1800 Result ===
[2025-08-15 11:27:49][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.470346               | 36.647651      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.868019        | 8.174419        | 13.534869      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.807449                  | 11.557936                 | 0.524562            | 123.064453         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.080138          | 268.736653       | 4.932277              | 242.719262           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.452607                      | 14.223174                    | 0.154747                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:30:15][base_learner.py:360][INFO] [RANK0]: === Training Iteration 1900 Result ===
[2025-08-15 11:30:15][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.525569               | 36.634320      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.858473        | 8.191280        | 13.523201      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.793412                  | 11.543564                 | 0.524463            | 126.397168         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.138021          | 268.462441       | 5.003008              | 237.424699           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.455823                      | 14.187594                    | 0.163551                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:35:48][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2000 Result ===
[2025-08-15 11:35:48][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 23.205876               | 36.660874      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.856973        | 8.173879        | 13.640871      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.783529                  | 11.644958                 | 0.525036            | 122.948232         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.081558          | 264.573120       | 4.884234              | 240.053109           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.452663                      | 14.056337                    | 0.171000                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:38:23][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2100 Result ===
[2025-08-15 11:38:23][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.163829               | 36.740659      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.843909        | 8.199801        | 13.725821      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.802241                  | 11.754524                 | 0.524621            | 119.860562         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.171283          | 258.332948       | 5.009169              | 236.629360           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.460205                      | 13.851285                    | 0.182603                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:43:35][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2200 Result ===
[2025-08-15 11:43:35][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.989397               | 36.700867      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.832821        | 8.233470        | 13.630853      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.790971                  | 11.648235                 | 0.523832            | 120.566017         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.229049          | 257.828175       | 5.029602              | 226.744444           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.468908                      | 13.887607                    | 0.149599                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:46:06][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2300 Result ===
[2025-08-15 11:46:06][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.958265               | 36.852812      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.900207        | 8.260914        | 13.778568      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.775020                  | 11.787894                 | 0.525055            | 120.873894         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.387548          | 263.424247       | 4.988312              | 234.358077           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.484006                      | 14.092013                    | 0.176240                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:51:03][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2400 Result ===
[2025-08-15 11:51:03][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 23.560608               | 36.824111      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.859996        | 8.277145        | 13.775004      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.775404                  | 11.776245                 | 0.523753            | 123.239894         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.368845          | 264.496552       | 5.074559              | 236.650796           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.485263                      | 14.074592                    | 0.163333                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:53:35][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2500 Result ===
[2025-08-15 11:53:35][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.113170               | 36.678118      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.837801        | 8.204474        | 13.591964      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.802760                  | 11.633912                 | 0.526614            | 124.386636         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.211293          | 265.576774       | 4.981045              | 234.574640           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.459426                      | 14.107843                    | 0.173309                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 11:58:58][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2600 Result ===
[2025-08-15 11:58:58][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 23.235926               | 36.748072      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.852426        | 8.227144        | 13.743183      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.775323                  | 11.728834                 | 0.525174            | 127.076930         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.323154          | 266.491369       | 4.966545              | 231.890436           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.473568                      | 14.146253                    | 0.159350                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:01:29][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2700 Result ===
[2025-08-15 12:01:29][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.152119               | 36.671427      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.854561        | 8.190872        | 13.577943      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.805542                  | 11.600718                 | 0.525785            | 124.958083         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.153883          | 270.193484       | 5.014613              | 237.877465           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.458294                      | 14.280896                    | 0.153863                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:06:39][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2800 Result ===
[2025-08-15 12:06:39][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.941216               | 36.675062      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.879519        | 8.218832        | 13.469007      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.808924                  | 11.505472                 | 0.524167            | 124.256826         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.176847          | 273.959423       | 4.936002              | 243.413359           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.458803                      | 14.411290                    | 0.153026                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:09:09][base_learner.py:360][INFO] [RANK0]: === Training Iteration 2900 Result ===
[2025-08-15 12:09:09][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.939416               | 36.603473      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.857379        | 8.168882        | 13.483271      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.802373                  | 11.517207                 | 0.524720            | 126.316587         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.095289          | 274.416817       | 4.859891              | 244.821179           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.451039                      | 14.371287                    | 0.150133                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:14:00][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3000 Result ===
[2025-08-15 12:14:00][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.293393               | 36.726386      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.843832        | 8.246499        | 13.642813      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.791802                  | 11.629005                 | 0.526298            | 127.386596         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.285748          | 270.867554       | 4.985387              | 239.693273           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.467231                      | 14.246928                    | 0.200961                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:16:32][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3100 Result ===
[2025-08-15 12:16:32][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.037966               | 36.669160      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.841932        | 8.217404        | 13.514754      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.818078                  | 11.546634                 | 0.526397            | 126.881970         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.135062          | 269.461043       | 4.959634              | 241.528936           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.456881                      | 14.206360                    | 0.167222                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:22:18][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3200 Result ===
[2025-08-15 12:22:18][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.633343               | 36.631804      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.842786        | 8.182518        | 13.528545      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.811920                  | 11.550185                 | 0.524897            | 123.253362         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.057410          | 269.379628       | 4.845461              | 242.052683           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.451412                      | 14.227395                    | 0.183891                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:24:47][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3300 Result ===
[2025-08-15 12:24:47][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.363110               | 36.644440      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.828484        | 8.199958        | 13.522193      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.818035                  | 11.572913                 | 0.524187            | 122.196419         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.163708          | 265.581352       | 4.947764              | 237.171628           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.455255                      | 14.095400                    | 0.174430                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:30:19][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3400 Result ===
[2025-08-15 12:30:19][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.621867               | 36.845246      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.905546        | 8.286398        | 13.629194      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.811745                  | 11.637604                 | 0.524858            | 124.462996         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.401515          | 270.408506       | 5.128000              | 237.221103           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.490693                      | 14.329281                    | 0.184331                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:32:51][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3500 Result ===
[2025-08-15 12:32:51][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.341788               | 36.769231      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.855160        | 8.284833        | 13.599128      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.801354                  | 11.615737                 | 0.524167            | 125.388942         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.335464          | 268.592563       | 5.107920              | 239.827326           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.480231                      | 14.196944                    | 0.152700                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:38:21][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3600 Result ===
[2025-08-15 12:38:21][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.286754               | 36.749788      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.862385        | 8.285922        | 13.537603      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.800271                  | 11.567650                 | 0.524897            | 126.162557         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.483428          | 272.970123       | 5.040315              | 240.092090           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.493039                      | 14.362241                    | 0.176607                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:40:52][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3700 Result ===
[2025-08-15 12:40:52][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.723185               | 36.675114      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.830509        | 8.227747        | 13.574304      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.799347                  | 11.601829                 | 0.523477            | 129.081616         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.233902          | 271.342216       | 5.147439              | 241.572370           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.467658                      | 14.254577                    | 0.203800                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:46:36][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3800 Result ===
[2025-08-15 12:46:36][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.313442               | 36.813774      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.842984        | 8.296285        | 13.720394      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.791940                  | 11.709563                 | 0.525075            | 125.927723         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.392046          | 270.236617       | 5.078101              | 238.536796           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.486431                      | 14.256685                    | 0.157361                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:49:06][base_learner.py:360][INFO] [RANK0]: === Training Iteration 3900 Result ===
[2025-08-15 12:49:06][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.979925               | 36.819221      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.887123        | 8.264271        | 13.749326      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.774419                  | 11.729928                 | 0.523595            | 125.984077         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.445076          | 271.142833       | 5.109159              | 241.988170           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.488771                      | 14.296534                    | 0.151405                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:54:53][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4000 Result ===
[2025-08-15 12:54:53][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.492831               | 36.678249      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.839028        | 8.256812        | 13.518735      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.799209                  | 11.513376                 | 0.525174            | 126.830641         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.326942          | 273.493269       | 4.959631              | 239.843500           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.470581                      | 14.373450                    | 0.167925                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 12:57:23][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4100 Result ===
[2025-08-15 12:57:23][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.539863               | 36.767080      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.834738        | 8.239100        | 13.715821      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.805072                  | 11.735851                 | 0.525253            | 128.773899         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.370502          | 273.153659       | 5.040574              | 244.176830           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.478505                      | 14.284796                    | 0.135641                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:02:56][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4200 Result ===
[2025-08-15 13:02:56][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.011531               | 36.806364      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.861074        | 8.287166        | 13.699402      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.783189                  | 11.698533                 | 0.525450            | 128.617427         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.439276          | 271.592890       | 5.054382              | 241.619447           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.486106                      | 14.273282                    | 0.152378                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:05:25][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4300 Result ===
[2025-08-15 13:05:25][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.485159               | 36.774399      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.846700        | 8.304205        | 13.561251      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.814913                  | 11.574432                 | 0.524661            | 124.626230         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.584754          | 273.475769       | 5.011840              | 241.170407           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.502362                      | 14.393078                    | 0.184300                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:11:43][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4400 Result ===
[2025-08-15 13:11:43][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.799811               | 36.809780      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.859238        | 8.265175        | 13.722369      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.793603                  | 11.746520                 | 0.524542            | 133.292021         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.310843          | 271.824083       | 5.021998              | 237.498255           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.480705                      | 14.240349                    | 0.188775                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:14:12][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4500 Result ===
[2025-08-15 13:14:12][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.980981               | 36.809405      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.840747        | 8.315415        | 13.655405      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.796102                  | 11.674281                 | 0.524720            | 127.329531         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.556463          | 270.068309       | 5.121215              | 239.521651           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.495573                      | 14.218220                    | 0.141479                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:19:06][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4600 Result ===
[2025-08-15 13:19:06][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.080201               | 36.979209      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.866736        | 8.375990        | 13.894504      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.776734                  | 11.843330                 | 0.525292            | 128.582567         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.726208          | 271.170846       | 5.190548              | 239.695971           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.516693                      | 14.273548                    | 0.168515                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:21:49][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4700 Result ===
[2025-08-15 13:21:49][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.609610               | 36.918695      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.852067        | 8.336394        | 13.811410      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.797144                  | 11.819306                 | 0.525410            | 127.191447         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.792259          | 272.917089       | 5.146667              | 240.039982           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.518281                      | 14.349885                    | 0.148293                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:27:10][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4800 Result ===
[2025-08-15 13:27:10][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.103236               | 36.861745      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.848086        | 8.324022        | 13.717047      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.805796                  | 11.715179                 | 0.525785            | 127.905796         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.632931          | 273.804230       | 5.138031              | 241.618064           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.504690                      | 14.381819                    | 0.181708                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:29:55][base_learner.py:360][INFO] [RANK0]: === Training Iteration 4900 Result ===
[2025-08-15 13:29:55][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.194018               | 36.947209      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.876680        | 8.362773        | 13.788319      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.793011                  | 11.769336                 | 0.525331            | 124.327461         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.699101          | 274.029882       | 5.247364              | 248.056559           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.513093                      | 14.377610                    | 0.135294                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:36:09][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5000 Result ===
[2025-08-15 13:36:09][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.543977               | 36.841238      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.827850        | 8.264840        | 13.845746      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.809287                  | 11.809736                 | 0.525391            | 129.599357         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.497041          | 272.703266       | 5.043002              | 241.926013           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.488537                      | 14.265237                    | 0.149410                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:38:51][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5100 Result ===
[2025-08-15 13:38:51][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.424256               | 36.906279      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.851484        | 8.331891        | 13.762219      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.819553                  | 11.752385                 | 0.524700            | 128.052175         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.677912          | 276.025063       | 5.167155              | 243.777026           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.503074                      | 14.427655                    | 0.179822                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:44:25][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5200 Result ===
[2025-08-15 13:44:25][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.117740               | 36.913562      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.889644        | 8.314252        | 13.750902      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.811556                  | 11.737767                 | 0.525943            | 126.880500         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.582860          | 279.057809       | 5.165070              | 249.777754           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.498478                      | 14.509030                    | 0.180377                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:47:10][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5300 Result ===
[2025-08-15 13:47:10][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.397566               | 36.844155      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.845294        | 8.309907        | 13.687487      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.819189                  | 11.697432                 | 0.523536            | 130.287931         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.629262          | 283.825709       | 5.269481              | 251.630672           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.504136                      | 14.659975                    | 0.182223                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:52:51][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5400 Result ===
[2025-08-15 13:52:51][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.513074               | 36.687165      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.821178        | 8.173861        | 13.715831      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.811784                  | 11.705160                 | 0.525095            | 131.725579         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.099906          | 275.899522       | 4.909094              | 248.092072           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.443954                      | 14.326065                    | 0.201292                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 13:55:46][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5500 Result ===
[2025-08-15 13:55:46][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.155248               | 36.829060      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.876600        | 8.269932        | 13.775455      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.779493                  | 11.736941                 | 0.524937            | 125.554369         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.464726          | 271.943612       | 5.011503              | 244.701290           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.478727                      | 14.299189                    | 0.197989                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:01:52][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5600 Result ===
[2025-08-15 14:01:52][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.120611               | 36.884602      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.856890        | 8.327050        | 13.781828      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.795913                  | 11.736632                 | 0.525134            | 126.914513         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.658854          | 275.590504       | 5.228321              | 247.556939           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.510272                      | 14.399032                    | 0.160996                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:04:50][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5700 Result ===
[2025-08-15 14:04:50][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.429517               | 36.898392      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.876793        | 8.305592        | 13.820557      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.791923                  | 11.779351                 | 0.524108            | 127.116470         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.553504          | 276.311310       | 5.051228              | 247.158508           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.495929                      | 14.435298                    | 0.164773                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:11:17][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5800 Result ===
[2025-08-15 14:11:17][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.019440               | 36.783441      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.832648        | 8.230503        | 13.762737      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.819156                  | 11.743082                 | 0.524680            | 128.284340         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.328244          | 270.946095       | 4.939804              | 241.715551           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.462350                      | 14.216050                    | 0.177568                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:14:14][base_learner.py:360][INFO] [RANK0]: === Training Iteration 5900 Result ===
[2025-08-15 14:14:14][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.631941               | 36.938993      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.873163        | 8.315240        | 13.872197      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.800645                  | 11.834226                 | 0.523339            | 124.430673         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.611269          | 269.991333       | 5.180776              | 245.033297           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.498728                      | 14.249552                    | 0.177244                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:19:49][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6000 Result ===
[2025-08-15 14:19:49][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.278829               | 36.868121      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.872544        | 8.285458        | 13.756578      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.811763                  | 11.735992                 | 0.525213            | 124.300813         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.509707          | 269.873133       | 4.933447              | 239.347875           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.485993                      | 14.248422                    | 0.177402                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:22:25][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6100 Result ===
[2025-08-15 14:22:25][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 22.054911               | 36.833242      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.844888        | 8.286768        | 13.769937      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.792222                  | 11.770222                 | 0.524325            | 128.389526         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.574929          | 271.751136       | 5.110190              | 238.624520           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.490195                      | 14.279713                    | 0.175347                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:27:24][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6200 Result ===
[2025-08-15 14:27:24][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.679457               | 36.808680      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.828285        | 8.271916        | 13.734745      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.816044                  | 11.736912                 | 0.524523            | 128.082834         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.599787          | 268.428206       | 5.097001              | 240.215184           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.490846                      | 14.145288                    | 0.163493                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:30:01][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6300 Result ===
[2025-08-15 14:30:01][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.598804               | 36.925772      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.858935        | 8.301643        | 13.909272      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.797315                  | 11.866750                 | 0.523872            | 124.414960         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.603220          | 269.660337       | 5.095798              | 245.713548           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.494744                      | 14.202995                    | 0.212785                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:36:17][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6400 Result ===
[2025-08-15 14:36:17][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.826457               | 36.903516      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.859896        | 8.329589        | 13.819903      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.786920                  | 11.790840                 | 0.524424            | 129.581681         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.613282          | 271.255332       | 5.172523              | 241.588193           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.501271                      | 14.234368                    | 0.176421                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:39:16][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6500 Result ===
[2025-08-15 14:39:16][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.650514               | 36.930594      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.843665        | 8.355513        | 13.827986      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.802423                  | 11.788710                 | 0.524819            | 124.082009         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.801729          | 275.787864       | 5.194538              | 247.513648           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.520651                      | 14.428749                    | 0.167276                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:45:55][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6600 Result ===
[2025-08-15 14:45:55][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.672391               | 36.880079      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.888476        | 8.352715        | 13.610818      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.806153                  | 11.623137                 | 0.524246            | 127.356589         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.642519          | 281.910095       | 5.332725              | 250.947565           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.510108                      | 14.636927                    | 0.176424                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:49:01][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6700 Result ===
[2025-08-15 14:49:01][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.310547               | 36.839600      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.828181        | 8.318937        | 13.723175      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.806024                  | 11.726617                 | 0.524010            | 133.371167         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.676255          | 277.837178       | 5.044681              | 246.689338           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.493331                      | 14.397405                    | 0.173929                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:55:55][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6800 Result ===
[2025-08-15 14:55:55][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.195594               | 36.900367      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.886110        | 8.326003        | 13.753624      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.788663                  | 11.747680                 | 0.524266            | 129.112428         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.508878          | 277.080314       | 5.036532              | 244.677938           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.493497                      | 14.459233                    | 0.148044                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 14:59:05][base_learner.py:360][INFO] [RANK0]: === Training Iteration 6900 Result ===
[2025-08-15 14:59:05][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 20.965058               | 36.931047      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.836935        | 8.319876        | 13.892011      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.805132                  | 11.880325                 | 0.526022            | 132.070461         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.669981          | 272.283042       | 5.194235              | 243.949155           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.499689                      | 14.218031                    | 0.161934                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 15:05:39][base_learner.py:360][INFO] [RANK0]: === Training Iteration 7000 Result ===
[2025-08-15 15:05:39][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.053244               | 36.849127      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.846139        | 8.328990        | 13.748816      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.782996                  | 11.717575                 | 0.524404            | 128.175523         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.695431          | 277.070623       | 5.018498              | 243.397636           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.505873                      | 14.472910                    | 0.185408                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 15:08:30][base_learner.py:360][INFO] [RANK0]: === Training Iteration 7100 Result ===
[2025-08-15 15:08:30][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.222358               | 36.986906      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.878301        | 8.383770        | 13.848038      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.788122                  | 11.804118                 | 0.523674            | 132.000977         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.880919          | 279.674125       | 5.184063              | 242.473489           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.524519                      | 14.548347                    | 0.177095                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 15:15:03][base_learner.py:360][INFO] [RANK0]: === Training Iteration 7200 Result ===
[2025-08-15 15:15:03][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.380503               | 36.930159      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.864725        | 8.336880        | 13.858620      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.785657                  | 11.818197                 | 0.523694            | 133.402996         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.839134          | 281.819999       | 5.184068              | 244.932935           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.520364                      | 14.591503                    | 0.165571                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 15:18:07][base_learner.py:360][INFO] [RANK0]: === Training Iteration 7300 Result ===
[2025-08-15 15:18:07][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.207119               | 36.918757      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.881894        | 8.348277        | 13.819327      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.767322                  | 11.766695                 | 0.524759            | 128.782351         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.707860          | 283.318975       | 5.076948              | 252.372445           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.516208                      | 14.671266                    | 0.169913                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 15:24:58][base_learner.py:360][INFO] [RANK0]: === Training Iteration 7400 Result ===
[2025-08-15 15:24:58][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.212237               | 36.922641      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.874798        | 8.342285        | 13.805904      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.784671                  | 11.784371                 | 0.523319            | 135.137160         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.750355          | 285.627758       | 5.243903              | 248.542418           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.509633                      | 14.710083                    | 0.212950                        |
+-------+-------------------------------+------------------------------+---------------------------------+

[2025-08-15 15:28:16][base_learner.py:360][INFO] [RANK0]: === Training Iteration 7500 Result ===
[2025-08-15 15:28:16][learner_hook.py:228][INFO] 
+-------+------------------------------+------------+-------------------------+----------------+
| Name  | collect_mcts_temperature_avg | cur_lr_avg | weighted_total_loss_avg | total_loss_avg |
+-------+------------------------------+------------+-------------------------+----------------+
| Value | 1.000000                     | 0.003000   | 21.894218               | 36.896928      |
+-------+------------------------------+------------+-------------------------+----------------+
+-------+-----------------+-----------------+----------------+----------------------+
| Name  | policy_loss_avg | reward_loss_avg | value_loss_avg | consistency_loss_avg |
+-------+-----------------+-----------------+----------------+----------------------+
| Value | 7.863451        | 8.311374        | 13.869012      | 0.000000             |
+-------+-----------------+-----------------+----------------+----------------------+
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Name  | afterstate_policy_loss_avg | afterstate_value_loss_avg | commitment_loss_avg | value_priority_avg |
+-------+----------------------------+---------------------------+---------------------+--------------------+
| Value | 13.772601                  | 11.829328                 | 0.524917            | 132.474675         |
+-------+----------------------------+---------------------------+---------------------+--------------------+
+-------+-------------------+------------------+-----------------------+----------------------+
| Name  | target_reward_avg | target_value_avg | predicted_rewards_avg | predicted_values_avg |
+-------+-------------------+------------------+-----------------------+----------------------+
| Value | 8.714726          | 282.694253       | 4.995439              | 253.553146           |
+-------+-------------------+------------------+-----------------------+----------------------+
+-------+-------------------------------+------------------------------+---------------------------------+
| Name  | transformed_target_reward_avg | transformed_target_value_avg | total_grad_norm_before_clip_avg |
+-------+-------------------------------+------------------------------+---------------------------------+
| Value | 1.500213                      | 14.586522                    | 0.156150                        |
+-------+-------------------------------+------------------------------+---------------------------------+

